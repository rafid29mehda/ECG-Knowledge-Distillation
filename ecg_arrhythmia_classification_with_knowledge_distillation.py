# -*- coding: utf-8 -*-
"""ECG Arrhythmia Classification with Knowledge Distillation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zvnqCTbjobuqI8mQcO-a_sm7Dvm17C3S
"""

!pip install wfdb numpy pandas scikit-learn tensorflow matplotlib
import wfdb
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt

# Download MIT-BIH Arrhythmia Database
!wget -r -N -c -np https://physionet.org/files/mitdb/1.0.0/ -P /content/mitdb

# Define records to use
records = ['100', '101', '102']
data = []
labels = []

# Load ECG signals and annotations
for record_name in records:
    record = wfdb.rdrecord(f'/content/mitdb/physionet.org/files/mitdb/1.0.0/{record_name}')
    annotation = wfdb.rdann(f'/content/mitdb/physionet.org/files/mitdb/1.0.0/{record_name}', 'atr')
    signal = record.p_signal[:, 0]  # Use first channel (MLII)
    ann_symbols = annotation.symbol
    ann_samples = annotation.sample

    # Extract 200-sample segments around each heartbeat
    for i, sample in enumerate(ann_samples):
        if sample > 100 and sample < len(signal) - 100:  # Ensure segment fits
            segment = signal[sample-100:sample+100]
            if len(segment) == 200:  # Ensure fixed length
                data.append(segment)
                labels.append(ann_symbols[i])

# Convert to numpy arrays
data = np.array(data)
labels = np.array(labels)

# Print shapes and unique labels to verify
print(f"Data shape: {data.shape}")
print(f"Labels shape: {labels.shape}")
print(f"Unique labels: {np.unique(labels)}")

# Simplify labels: 'N' (normal) as 0, others (abnormal) as 1
binary_labels = np.where(labels == 'N', 0, 1)

# Normalize the ECG signals
scaler = StandardScaler()
data_normalized = scaler.fit_transform(data)

# Reshape data for CNN (samples, length, channels)
data_normalized = data_normalized.reshape(data_normalized.shape[0], data_normalized.shape[1], 1)

# Split into train (70%), validation (15%), and test (15%) sets
X_train, X_temp, y_train, y_temp = train_test_split(data_normalized, binary_labels, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Print shapes to verify
print(f"Training data shape: {X_train.shape}")
print(f"Validation data shape: {X_val.shape}")
print(f"Test data shape: {X_test.shape}")
print(f"Training labels distribution: {np.bincount(y_train)}")

def build_teacher_model():
    model = models.Sequential([
        layers.Conv1D(64, kernel_size=5, activation='relu', input_shape=(200, 1)),
        layers.MaxPooling1D(pool_size=2),
        layers.Conv1D(128, kernel_size=5, activation='relu'),
        layers.MaxPooling1D(pool_size=2),
        layers.Conv1D(256, kernel_size=5, activation='relu'),
        layers.MaxPooling1D(pool_size=2),
        layers.Flatten(),
        layers.Dense(512, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(1, activation='sigmoid')  # Binary classification
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Build and summarize the teacher model
teacher_model = build_teacher_model()
teacher_model.summary()

# Train the teacher model
history = teacher_model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=32,
    verbose=1
)

# Plot training history
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Teacher Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Teacher Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

def build_student_model():
    model = models.Sequential([
        layers.Conv1D(16, kernel_size=5, activation='relu', input_shape=(200, 1)),
        layers.MaxPooling1D(pool_size=2),
        layers.Conv1D(32, kernel_size=5, activation='relu'),
        layers.MaxPooling1D(pool_size=2),
        layers.Flatten(),
        layers.Dense(64, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(1, activation='sigmoid')
    ])
    return model

# Build and summarize the student model
student_model = build_student_model()
student_model.summary()

import tensorflow as tf
import matplotlib.pyplot as plt

# Define KD loss function
def distillation_loss(y_true, y_pred, teacher_model, x, temperature=5.0, alpha=0.5):
    # Reshape y_true to match y_pred's shape (None, 1)
    y_true = tf.reshape(y_true, [-1, 1])

    # Get teacher predictions (logits before sigmoid)
    teacher_logits = teacher_model(x, training=False)

    # Compute soft labels and soft predictions
    soft_labels = tf.nn.sigmoid(teacher_logits / temperature)
    soft_pred = tf.nn.sigmoid(y_pred / temperature)

    # Distillation loss (between soft labels and soft predictions)
    distillation_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(soft_labels, soft_pred))

    # Standard loss (between true labels and student predictions)
    standard_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)

    # Combine losses
    return alpha * distillation_loss + (1 - alpha) * standard_loss

# Wrapper function to pass teacher model and inputs
def get_distillation_loss(teacher_model, temperature=5.0, alpha=0.5):
    def loss_fn(y_true, y_pred, x):
        return distillation_loss(y_true, y_pred, teacher_model, x, temperature, alpha)
    return loss_fn

# Prepare datasets with drop_remainder=True to ensure consistent batch sizes
batch_size = 32
train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size, drop_remainder=True)
val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size, drop_remainder=True)

# Build and compile student model
student_model = build_student_model()
student_model.compile(
    optimizer='adam',
    loss=lambda y_true, y_pred: get_distillation_loss(teacher_model)(y_true, y_pred, X_train[:batch_size]),
    metrics=['accuracy']
)

# Train the student with KD
history_kd = student_model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=20,
    verbose=1
)

# Plot training history
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history_kd.history['loss'], label='Training Loss')
plt.plot(history_kd.history['val_loss'], label='Validation Loss')
plt.title('Student Model (KD) Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_kd.history['accuracy'], label='Training Accuracy')
plt.plot(history_kd.history['val_accuracy'], label='Validation Accuracy')
plt.title('Student Model (KD) Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

from sklearn.metrics import classification_report

# Evaluate teacher model
teacher_pred = (teacher_model.predict(X_test) > 0.5).astype(int)
print("Teacher Model Evaluation:")
print(classification_report(y_test, teacher_pred, target_names=['Normal', 'Abnormal']))

# Evaluate student model
student_pred = (student_model.predict(X_test) > 0.5).astype(int)
print("Student Model (KD) Evaluation:")
print(classification_report(y_test, student_pred, target_names=['Normal', 'Abnormal']))

# Compare model sizes
teacher_params = teacher_model.count_params()
student_params = student_model.count_params()
print(f"Teacher model parameters: {teacher_params}")
print(f"Student model parameters: {student_params}")
print(f"Parameter reduction: {((teacher_params - student_params) / teacher_params) * 100:.2f}%")

# Save models
teacher_model.save('/content/teacher_model.h5')
student_model.save('/content/student_model.h5')

# Save classification reports
with open('/content/classification_report.txt', 'w') as f:
    f.write("Teacher Model Evaluation:\n")
    f.write(classification_report(y_test, teacher_pred, target_names=['Normal', 'Abnormal']))
    f.write("\nStudent Model (KD) Evaluation:\n")
    f.write(classification_report(y_test, student_pred, target_names=['Normal', 'Abnormal']))
    f.write(f"\nTeacher model parameters: {teacher_params}\n")
    f.write(f"Student model parameters: {student_params}\n")
    f.write(f"Parameter reduction: {((teacher_params - student_params) / teacher_params) * 100:.2f}%")


# Download files
from google.colab import files
files.download('/content/teacher_model.h5')
files.download('/content/student_model.h5')
files.download('/content/classification_report.txt')









